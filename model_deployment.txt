In order to deploy our finetuned model with OpenAI compatible API, follow the steps below (On a single A100 GPU server):

On a server with pytorch version 2.1 and cuda 11.8.0:

1) pip install vllm==0.3.3

2) apt update

3) apt install tmux

4) tmux

5) python -m vllm.entrypoints.openai.api_server --model AI4DS/NL2SQL_DeepSeek_33B --load-format safetensors --dtype bfloat16 --max-model-len 8192

6) Put the server URI in the run_main.sh file for the "candidate_generation" node as follows: 

    "candidate_generation"{
        "engine": "'${engine6}'",
        "temperature": 0.0,
        "base_uri": "https://jlpiastvutqow3-8000.proxy.runpod.net", ---> put the server URI here without /v1
        "sampling_count": 1
    }